# Generated by Django 3.2.8 on 2022-01-15 07:25


from django.db import migrations
import requests
import json
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk

# nltk needs to be dowloaded during migration
# nltk.download('punkt')
# nltk.download('stopwords')


class Migration(migrations.Migration):

    dependencies = [
        ('suggestapp', '0001_initial'),
    ]

    def insert_default_articles(apps, schema_editor):
        apiKey = "0030269e63c084891d5a7e14e5565770"
        list = ['Algorithms', "Artificial Intelligence",
                "Networking", "Wireless Communication", "Data Science", "Molecular Communication", "Computer Science"]
        keywordList = []
        doilist = []
        for item in list:
            url = ("https://api.elsevier.com/content/search/sciencedirect?query=" +
                   item+"&apiKey=7f59af901d2d86f78a1fd60c1bf9426a&count=100")
            response = requests.request("GET", url)
            result = json.loads(response.text.encode(
                'utf-8'))
            if 'search-results' in result:
                result = result['search-results']
                if 'entry' in result:
                    result = result['entry']
                else:
                    pass
            else:
                pass
            for i in result:
                doi = i['prism:doi']
                doilist.append(doi)
                keywordList.append(item)
        dictionary = dict(zip(doilist, keywordList))
        dictionary.update(
            {'10.1016/j.nancom.2018.10.001': 'Molecular Communication',
             '10.1016/j.dsp.2021.103185': 'Molecular Communication',
             '10.1016/j.nancom.2012.01.005': 'Molecular Communication',
             '10.1016/j.nancom.2010.07.002': 'Molecular Communication'})
        for doi in dictionary:
            keyword = dictionary[doi]
            url = ("https://api.elsevier.com/content/article/doi/"+doi+"?apiKey="+apiKey+"&httpAccept=application/json"
                   )
            response = requests.request("GET", url)
            result = json.loads(response.text.encode(
                'utf-8'))['full-text-retrieval-response']['coredata']
            if result['dc:description'] != None:
                abstract = result['dc:description']
                lowerCase = abstract.lower()
                text_tokens = word_tokenize(lowerCase)
                stops = set(stopwords.words('english'))
                tokens_without_sw = [
                    word for word in text_tokens if not word in stops]
                noStop = ' '.join(tokens_without_sw)
                tokenizer = nltk.RegexpTokenizer(r"\w+")
                new_words = tokenizer.tokenize(noStop)
                wordsFiltered = " ".join(new_words)
                vectorizer = TfidfVectorizer()
                vectors = vectorizer.fit_transform([wordsFiltered])
                feature_names = vectorizer.get_feature_names()
                dense = vectors.todense()
                denselist = dense.tolist()
                for part in denselist:
                    dense = part
                tfidResults = {feature_names[part]: dense[part]
                               for part in range(len(feature_names))}
                vectorized = " ".join(tfidResults)
                author = []
                if result['dc:creator'] == None:
                    pass
                else:
                    res = result['dc:creator']
                    if type(res) == dict:
                        authors = result['dc:creator']['$']
                    else:
                        for auth in result['dc:creator']:
                            author.append(auth['$'])
                            authors = (',').join(author)
                doiSave = result['prism:doi']
                date = result['prism:coverDate']
                link = result['link'][1]['@href']
                title = result['dc:title']
            else:
                pass
            content = apps.get_model('suggestapp', 'article')
            content = content(doi=doiSave, title=title, authors=authors,
                              abstract=abstract, term=keyword, date=date,
                              link=link, vectorized=vectorized)
            content.save()

    operations = [
        migrations.RunPython(insert_default_articles),
    ]
